# Лабораторная работа №1, MNIST
Цель:  настоящей работы состоит в том, чтобы изучить метод обратного распространения ошибки для обучения глубоких нейронных сетей на примере двухслойной полностью связанной сети (один скрытый слой).

В данной работе реализована нейронная сеть для классификации рукописных цифр набора данных MNIST.

Файл `main_project.py` содержит реализацию нейронной сети и её обучение на изображениях цифр из датасета MNIST, сохранённого в формате `.png`. Скрипт запускается через терминал с параметрами и поддерживает два режима работы. В режиме обучения, при передаче соответствующих аргументов (`--train`, `--path_to_dataset`, `--learning_rate`, `--hidden_size`, `--epochs`), происходит обучение модели на основе переданных данных, выводятся метрики (`loss`, `accuracy`, `val accuracy`), и сохраняются веса в файл `weights.npz`. Во втором режиме — классификации — можно указать путь к изображению (например, `7.png`), и скрипт предскажет, какая цифра изображена, а при добавлении флага --probs дополнительно выведет вероятности принадлежности изображения к каждому из 10 классов (от 0 до 9).

Скрипт разработан для запуска через терминал, работает в консоли Visual Studio Code и не требует GUI. На выходе пользователь получает обученную модель, может классифицировать произвольные изображения с цифрами, видеть предсказанную метку и распределение вероятностей по классам.

# Установка и запуск проекта

1. Установите Python. Убедитесь, что у вас установлен Python 3.9+ (Проект протестирован на `Python 3.11.9`). Скачайте: https://www.python.org/downloads/.

2. Создайте виртуальное окружение (рекомендуется).
```
python -m venv venv
venv\Scripts\activate  # Windows
# или
source venv/bin/activate  # macOS/Linux
```
3. Установите зависимости (приложен файл `requirements.txt`).
```
pip install -r requirements.txt
```

# Генерация датасета

При первом запуске `main_project.py` автоматически:

- скачает оригинальный датасет MNIST;

- преобразует его в изображения `.png`;

- сохранит по папкам: `mnist_data/train/[0-9]/`, `mnist_data/valid/[0-9]/` и `mnist_data/test/[0-9]/`.
Пример структуры после генерации:
```
mnist_data/
├── train/
│   └── 0/, 1/, ..., 9/
├── valid/
│   └── 0/, ..., 9/
└── test/
    └── 0/, ..., 9/
```

# Обучение модели

Запустите скрипт для обучения с параметрами:
```
python main_project.py --train --path_to_dataset "mnist_data" --learning_rate 0.05 --hidden_size "[1024]" --epochs 50
```

| Аргумент            | Описание                                                             |
| ------------------- | -------------------------------------------------------------------- |
| `--train`           | Включить режим обучения                                              |
| `--path_to_dataset` | Путь к папке с PNG-датасетом                                         |
| `--learning_rate`   | Скорость обучения (0.001 по умолчанию)                               |
| `--hidden_size`     | Скрытые слои нейросети, например `[512]`, `[128, 64]`, `[1024]`      |
| `--epochs`          | Кол-во эпох обучения (50 по умолчанию)                               |
| `--weights_path`    | (Опционально) Путь для сохранения весов (`weights.npz` по умолчанию) |

Ниже приведен пример вывода для текущего скрипта:
```
Epoch 1/50 | Loss: 0.2423 | Train Acc: 0.0725 | Val Acc: 0.1280
Epoch 2/50 | Loss: 0.2290 | Train Acc: 0.1203 | Val Acc: 0.2056
Epoch 3/50 | Loss: 0.2193 | Train Acc: 0.1981 | Val Acc: 0.3117
Epoch 4/50 | Loss: 0.2110 | Train Acc: 0.3054 | Val Acc: 0.4068
Epoch 5/50 | Loss: 0.2034 | Train Acc: 0.3998 | Val Acc: 0.4820
Epoch 6/50 | Loss: 0.1963 | Train Acc: 0.4748 | Val Acc: 0.5416
Epoch 7/50 | Loss: 0.1896 | Train Acc: 0.5310 | Val Acc: 0.5865
Epoch 8/50 | Loss: 0.1833 | Train Acc: 0.5741 | Val Acc: 0.6242
Epoch 9/50 | Loss: 0.1773 | Train Acc: 0.6075 | Val Acc: 0.6526
Epoch 10/50 | Loss: 0.1716 | Train Acc: 0.6357 | Val Acc: 0.6751
Epoch 11/50 | Loss: 0.1662 | Train Acc: 0.6570 | Val Acc: 0.6952
Epoch 12/50 | Loss: 0.1611 | Train Acc: 0.6758 | Val Acc: 0.7115
Epoch 13/50 | Loss: 0.1563 | Train Acc: 0.6915 | Val Acc: 0.7239
Epoch 14/50 | Loss: 0.1518 | Train Acc: 0.7043 | Val Acc: 0.7341
Epoch 15/50 | Loss: 0.1475 | Train Acc: 0.7159 | Val Acc: 0.7451
Epoch 16/50 | Loss: 0.1434 | Train Acc: 0.7263 | Val Acc: 0.7537
Epoch 17/50 | Loss: 0.1395 | Train Acc: 0.7342 | Val Acc: 0.7610
Epoch 18/50 | Loss: 0.1359 | Train Acc: 0.7416 | Val Acc: 0.7687
Epoch 19/50 | Loss: 0.1324 | Train Acc: 0.7489 | Val Acc: 0.7749
Epoch 20/50 | Loss: 0.1291 | Train Acc: 0.7545 | Val Acc: 0.7803
Epoch 21/50 | Loss: 0.1260 | Train Acc: 0.7598 | Val Acc: 0.7861
Epoch 22/50 | Loss: 0.1231 | Train Acc: 0.7653 | Val Acc: 0.7908
Epoch 23/50 | Loss: 0.1203 | Train Acc: 0.7700 | Val Acc: 0.7952
Epoch 24/50 | Loss: 0.1177 | Train Acc: 0.7747 | Val Acc: 0.7992
Epoch 25/50 | Loss: 0.1152 | Train Acc: 0.7785 | Val Acc: 0.8030
Epoch 26/50 | Loss: 0.1128 | Train Acc: 0.7825 | Val Acc: 0.8065
Epoch 27/50 | Loss: 0.1105 | Train Acc: 0.7853 | Val Acc: 0.8105
Epoch 28/50 | Loss: 0.1083 | Train Acc: 0.7887 | Val Acc: 0.8129
Epoch 29/50 | Loss: 0.1063 | Train Acc: 0.7917 | Val Acc: 0.8168
Epoch 30/50 | Loss: 0.1043 | Train Acc: 0.7943 | Val Acc: 0.8192
Epoch 31/50 | Loss: 0.1025 | Train Acc: 0.7974 | Val Acc: 0.8226
Epoch 32/50 | Loss: 0.1007 | Train Acc: 0.8005 | Val Acc: 0.8261
Epoch 33/50 | Loss: 0.0990 | Train Acc: 0.8032 | Val Acc: 0.8277
Epoch 34/50 | Loss: 0.0973 | Train Acc: 0.8055 | Val Acc: 0.8306
Epoch 35/50 | Loss: 0.0958 | Train Acc: 0.8079 | Val Acc: 0.8324
Epoch 36/50 | Loss: 0.0943 | Train Acc: 0.8103 | Val Acc: 0.8349
Epoch 37/50 | Loss: 0.0929 | Train Acc: 0.8122 | Val Acc: 0.8366
Epoch 38/50 | Loss: 0.0915 | Train Acc: 0.8144 | Val Acc: 0.8381
Epoch 39/50 | Loss: 0.0902 | Train Acc: 0.8165 | Val Acc: 0.8400
Epoch 40/50 | Loss: 0.0889 | Train Acc: 0.8185 | Val Acc: 0.8417
Epoch 41/50 | Loss: 0.0877 | Train Acc: 0.8204 | Val Acc: 0.8428
Epoch 42/50 | Loss: 0.0865 | Train Acc: 0.8219 | Val Acc: 0.8440
Epoch 43/50 | Loss: 0.0854 | Train Acc: 0.8238 | Val Acc: 0.8464
Epoch 44/50 | Loss: 0.0843 | Train Acc: 0.8253 | Val Acc: 0.8475
Epoch 45/50 | Loss: 0.0833 | Train Acc: 0.8266 | Val Acc: 0.8488
Epoch 46/50 | Loss: 0.0823 | Train Acc: 0.8281 | Val Acc: 0.8501
Epoch 47/50 | Loss: 0.0813 | Train Acc: 0.8296 | Val Acc: 0.8513
Epoch 48/50 | Loss: 0.0804 | Train Acc: 0.8311 | Val Acc: 0.8527
Epoch 49/50 | Loss: 0.0795 | Train Acc: 0.8321 | Val Acc: 0.8539
Epoch 50/50 | Loss: 0.0786 | Train Acc: 0.8332 | Val Acc: 0.8542
Test accuracy: 0.8485
Test precision: 0.8488
Test recall: 0.8451
Test F1-score: 0.8446
Confusion Matrix:
 [[ 930    0    5    4    0   14   20    1    6    0]
 [   0 1101    3    3    0    1    5    1   21    0]
 [  29   29  824   27   14    1   28   21   51    8]
 [   5   14    2    2  824    0   23    2    8  102]
 [  30   22    7  106   19  581   25   14   53   35]
 [  16   12   16    2   16   20  872    1    3    0]
 [   7   42   22    2   10    0    1  889   14   41]
 [  12   27   10   60   16   39   19   19  747   25]
 [  21   16    7   12   61    9    3   37   11  832]]
```

# Классификация изображений
Запустите классификацию, указав путь к изображению:
```
python main_project.py "ваш\путь\image.png"
```
| Опция            | Описание                                                        |
| ---------------- | --------------------------------------------------------------- |
| `--probs`        | Показать вероятности для всех классов                           |
| `--weights_path` | Загрузить веса из указанного файла (`weights.npz` по умолчанию) |

Требования к изображению:
- Формат: PNG, JPG, BMP
- Размер: 28x28 (если больше/меньше — будет автоматически изменён)

# Пример распознавания цифры
Распознаем цифру "7", для этого запустим следующий скрипт:
```
python main_project.py "C:\Users\ваш\путь\7.png"
```
Вывод:
```
Predicted digit: 7
```

# Пример вывода вероятностей по всем классам
Выведем вероятности по всем классам для цифры "0", для этого запустим следующий скрипт:

```
python main_project.py "C:\Users\ваш\путь\0.png" --probs
```
Вывод:
```
Class probabilities:
0: 0.8038
1: 0.0026
2: 0.0124
3: 0.0063
4: 0.0051
5: 0.0983
6: 0.0420
7: 0.0169
8: 0.0053
9: 0.0073
```

# Заключение
В ходе данной лабораторной работы была реализована и протестирована нейронная сеть, предназначенная для распознавания изображений цифр из набора MNIST. Работа выполнена в среде Visual Studio Code, проект организован в виде одного консольного Python-скрипта с возможностью запуска различных режимов через аргументы командной строки. Одним из ключевых достижений стало ручное внедрение алгоритма обратного распространения ошибки (backpropagation) — это фундаментальный метод для обучения многослойных нейронных сетей. Его реализация обеспечила корректную настройку весов и смещений сети на основе градиентного спуска, что позволило добиться устойчивого снижения функции потерь и роста точности на валидационных данных. Финальные результаты обучения продемонстрировали достижение точности около 85% на тестовой выборке, что подтверждает корректность как архитектуры модели, так и работы backpropagation.

Таким образом, проделанная работа не только углубила понимание теоретических основ машинного обучения, но и позволила на практике реализовать один из центральных алгоритмов обучения нейросетей — обратное распространение ошибки, что делает проект ценным учебным инструментом и прочной основой для дальнейших улучшений.
